{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8102ab4",
   "metadata": {},
   "source": [
    "# Battery State of Charge (SoC) Estimation using Deep Learning\n",
    "\n",
    "This notebook implements multiple deep learning models for battery State of Charge estimation using LSTM, Bidirectional LSTM, GRU, Bidirectional GRU, and 1D CNN architectures with Bayesian hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39262f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import math\n",
    "import os\n",
    "import ntpath\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from importlib import reload\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, mixed_precision\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten, Bidirectional, GRU\n",
    "from keras.optimizers import SGD, Adam\n",
    "import np_utils\n",
    "from keras.layers import LSTM, Embedding, RepeatVector, TimeDistributed, Masking\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "import matplotlib.pyplot as plt\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Check if GPU is available\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Check if running in Google Colab\n",
    "IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/battery-state-estimation/battery-state-estimation/\"\n",
    "else:\n",
    "    data_path = \"../\"\n",
    "\n",
    "# Add the data path to sys.path for module imports\n",
    "sys.path.append(data_path)\n",
    "from data_processing.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from data_processing.model_data_handler import ModelDataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fe526",
   "metadata": {},
   "source": [
    "### Config logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the logging module (if needed).\n",
    "#Set up a consistent format for log messages, including timestamps and severity levels.\n",
    "#Ensure all messages (from DEBUG level onward) are recorded.\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG, datefmt='%Y/%m/%d %H:%M:%S')\n",
    "#DEBUG is the lowest level, meaning all messages (including DEBUG, INFO, WARNING, ERROR, and CRITICAL) will be logged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0726cc6",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732766f9",
   "metadata": {},
   "source": [
    "### Initialize the data object\n",
    "\n",
    "Load the cycle and capacity data to memory based on the specified chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d337c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UniboPowertoolsData(\n",
    "    test_types=['S'],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fd020",
   "metadata": {},
   "source": [
    "### Determine the training and testing datasets\n",
    "\n",
    "Prepare the training and testing data for model data handler to load the model input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_test_names = [\n",
    "    '000-DM-3.0-4019-S', \n",
    "    '001-DM-3.0-4019-S', \n",
    "    '002-DM-3.0-4019-S', \n",
    "    '006-EE-2.85-0820-S', \n",
    "    '007-EE-2.85-0820-S', \n",
    "    '018-DP-2.00-1320-S', \n",
    "    '019-DP-2.00-1320-S',\n",
    "    '036-DP-2.00-1720-S',\n",
    "    '037-DP-2.00-1720-S', \n",
    "    '038-DP-2.00-2420-S', \n",
    "    '040-DM-4.00-2320-S',\n",
    "    '042-EE-2.85-0820-S', \n",
    "    '045-BE-2.75-2019-S'\n",
    "]\n",
    "\n",
    "test_data_test_names = [\n",
    "    '003-DM-3.0-4019-S',\n",
    "    '008-EE-2.85-0820-S',\n",
    "    '039-DP-2.00-2420-S', \n",
    "    '041-DM-4.00-2320-S',    \n",
    "]\n",
    "\n",
    "dataset.prepare_data(train_data_test_names, test_data_test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c50381",
   "metadata": {},
   "source": [
    "### Initialize the model data handler\n",
    "\n",
    "Model data handler will be used to get the model input and output data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdh = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b152b2",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = mdh.get_discharge_whole_cycle(soh = False, output_capacity = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_y = mdh.keep_only_capacity(train_y, is_multiple_output = True)\n",
    "test_y = mdh.keep_only_capacity(test_y, is_multiple_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055306e",
   "metadata": {},
   "source": [
    "# Sliding Windows Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73364bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sliding windows to train_x and test_x\n",
    "window_size = 30\n",
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543920ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#at the start of each array pad for window length the first number of the array\n",
    "train_x= np.array([np.vstack(([cycle[0]]*(window_size-1), cycle))for cycle in train_x])\n",
    "train_y= np.array([np.hstack(([soc[0]]*(window_size-1) , soc)) for soc in train_y])\n",
    "test_x= np.array([np.vstack(([cycle[0]]*(window_size-1), cycle))for cycle in test_x])\n",
    "test_y= np.array([np.hstack(([soc[0]]*(window_size-1) , soc)) for soc in test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train X shape: {train_x.shape}\")\n",
    "print(f\"Train Y shape: {train_y.shape}\")\n",
    "print(f\"Test X shape: {test_x.shape}\")\n",
    "print(f\"Test Y shape: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sliding windows function\n",
    "def create_sliding_windows(data, labels, window_size=30, stride=1):\n",
    "    sliding_windows = []\n",
    "    aligned_labels = []\n",
    "    skipped_samples = 0\n",
    "\n",
    "    for i, sample in enumerate(data):\n",
    "        sample_labels = labels[i]  # Labels for the current sample (time_steps,)\n",
    "        if len(sample) < window_size:\n",
    "            skipped_samples += 1\n",
    "            continue\n",
    "        #find the number of padding start indices\n",
    "        padding_start_index = len(sample_labels)\n",
    "        for a in range(len(sample_labels)):\n",
    "            if sample_labels[a] == 1 and sample_labels[a - 1] == 1:\n",
    "                padding_start_index = a-1\n",
    "                break\n",
    "        for j in range(0, padding_start_index - window_size + 1, stride):\n",
    "            # Extract window and corresponding label (last time step of the window)\n",
    "            sliding_windows.append(sample[j:j + window_size])\n",
    "            aligned_labels.append(sample_labels[j + window_size - 1])  # Use label at the end of the window\n",
    "\n",
    "    if skipped_samples > 0:\n",
    "        logging.warning(f\"Skipped {skipped_samples} samples due to insufficient length for window size {window_size}.\")\n",
    "\n",
    "    return np.array(sliding_windows), np.array(aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a00d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sliding windows for train and test data\n",
    "train_x_windowed, train_y_aligned = create_sliding_windows(train_x, train_y, window_size=window_size, stride=stride)\n",
    "test_x_windowed, test_y_aligned = create_sliding_windows(test_x, test_y, window_size=window_size, stride=stride)\n",
    "\n",
    "# Update train_x, train_y, test_x, test_y\n",
    "train_x = train_x_windowed\n",
    "train_y = train_y_aligned\n",
    "test_x = test_x_windowed\n",
    "test_y = test_y_aligned\n",
    "\n",
    "# Log the new shapes after applying sliding windows\n",
    "logging.info(\"After sliding windows - Train x: %s, Train y: %s | Test x: %s, Test y: %s\" %\n",
    "             (train_x.shape, train_y.shape, test_x.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595dc6e",
   "metadata": {},
   "source": [
    "# Model Architectures\n",
    "\n",
    "## Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bi_lstm_model(hp):\n",
    "    \"\"\"Build Bidirectional LSTM model with hyperparameter tuning\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tunable Bidirectional LSTM layers\n",
    "    for i in range(hp.Int('lstm_layers', 1, 3)):  # Number of Bidirectional LSTM layers (1 to 3)\n",
    "        if i == 0:\n",
    "            model.add(layers.Bidirectional(\n",
    "                layers.LSTM(\n",
    "                    units=hp.Int(f'units_{i}', 32, 256, step=32),  # Tunable number of units\n",
    "                    activation='tanh',\n",
    "                    input_shape=(train_x.shape[1], train_x.shape[2]),  # Input shape for the first LSTM layer\n",
    "                    return_sequences=True if hp.Int('lstm_layers', 1, 3) > 1 else False  # Return sequences if more layers follow\n",
    "                )\n",
    "            ))\n",
    "        else:\n",
    "            model.add(layers.Bidirectional(\n",
    "                layers.LSTM(\n",
    "                    units=hp.Int(f'units_{i}', 32, 256, step=32),  # Tunable number of units\n",
    "                    activation='tanh',\n",
    "                    return_sequences=True if i < hp.Int('lstm_layers', 1, 3) - 1 else False  # Return sequences if not the last layer\n",
    "                )\n",
    "            ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)  # Tunable dropout rate\n",
    "        ))\n",
    "    \n",
    "    # Tunable dense layers\n",
    "    for j in range(hp.Int('dense_layers', 1, 3)):  # Number of dense layers (1 to 3)\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'dense_units_{j}', 64, 512, step=32),  # Tunable number of units\n",
    "            activation='selu'\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f'dense_dropout_{j}', 0.0, 0.5, step=0.1)  # Tunable dropout rate\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='linear'))  # Output layer\n",
    "    \n",
    "    # Tunable learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',\n",
    "        metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7629e",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(hp):\n",
    "    \"\"\"Build LSTM model with hyperparameter tuning\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tunable LSTM layers\n",
    "    for i in range(hp.Int('lstm_layers', 1, 3)):  # Number of LSTM layers (1 to 3)\n",
    "        if i == 0:\n",
    "            model.add(layers.LSTM(\n",
    "                units=hp.Int(f'units_{i}', 32, 256, step=32),  # Tunable number of units\n",
    "                activation='tanh',\n",
    "                input_shape=(train_x.shape[1], train_x.shape[2]),  # Input shape for the first LSTM layer\n",
    "                return_sequences=True if hp.Int('lstm_layers', 1, 3) > 1 else False  # Return sequences if more layers follow\n",
    "            ))\n",
    "        else:\n",
    "            model.add(layers.LSTM(\n",
    "                units=hp.Int(f'units_{i}', 32, 256, step=32),  # Tunable number of units\n",
    "                activation='tanh',\n",
    "                return_sequences=True if i < hp.Int('lstm_layers', 1, 3) - 1 else False  # Return sequences if not the last layer\n",
    "            ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)  # Tunable dropout rate\n",
    "        ))\n",
    "    \n",
    "    # Tunable dense layers\n",
    "    for j in range(hp.Int('dense_layers', 1, 3)):  # Number of dense layers (1 to 3)\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'dense_units_{j}', 64, 512, step=32),  # Tunable number of units\n",
    "            activation='selu'\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f'dense_dropout_{j}', 0.0, 0.5, step=0.1)  # Tunable dropout rate\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='linear'))  # Output layer\n",
    "    \n",
    "    # Tunable learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',\n",
    "        metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af08d8",
   "metadata": {},
   "source": [
    "## 1D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d33e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_model(hp):\n",
    "    \"\"\"Build 1D CNN model with hyperparameter tuning\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tunable Conv1D layers\n",
    "    for i in range(hp.Int('conv_layers', 1, 3)):\n",
    "        if i == 0:\n",
    "            model.add(layers.Conv1D(\n",
    "                filters=hp.Int(f'filters_{i}', 32, 256, step=32),\n",
    "                kernel_size=hp.Int(f'kernel_size_{i}', 2, 5),\n",
    "                activation='selu',\n",
    "                padding='same',\n",
    "                input_shape=(train_x.shape[1], train_x.shape[2])\n",
    "            ))\n",
    "        else:\n",
    "            model.add(layers.Conv1D(\n",
    "                filters=hp.Int(f'filters_{i}', 32, 256, step=32),\n",
    "                kernel_size=hp.Int(f'kernel_size_{i}', 2, 5),\n",
    "                activation='selu',\n",
    "                padding='same'\n",
    "            ))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Tunable dense layers\n",
    "    for j in range(hp.Int('dense_layers', 1, 3)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'dense_units_{j}', 64, 512, step=32),\n",
    "            activation='selu'\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f'dropout_{j}', 0.0, 0.5, step=0.1)\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    # Tunable learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',\n",
    "        metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d4fd9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10129bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EXPERIMENT = \"lstm_soc_estimation\"\n",
    "experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "\n",
    "# Set GPU device (adjust according to your setup)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d184c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model architecture (uncomment the desired model)\n",
    "build_model = build_lstm_model  # Default to LSTM\n",
    "# build_model = build_bi_lstm_model  # Uncomment for Bidirectional LSTM\n",
    "# build_model = build_1d_cnn_model  # Uncomment for 1D CNN\n",
    "\n",
    "# Tuner configuration\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='bayesian_optimization',\n",
    "    project_name=experiment_name,\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "# Display tuner search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fef35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start hyperparameter tuning\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "tuner.search(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=100,\n",
    "    batch_size=2048,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Hyperparameter tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4841df9",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678064c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_models(tuner, experiment_name, num_models=5):\n",
    "    \"\"\"Evaluate the best models from hyperparameter tuning\"\"\"\n",
    "    best_models = tuner.get_best_models(num_models=num_models)\n",
    "    results = []\n",
    "    \n",
    "    for i, model in enumerate(best_models, 1):\n",
    "        print(f\"Evaluating model {i}/{num_models}...\")\n",
    "        \n",
    "        val_metrics = model.evaluate(train_x, train_y, verbose=0)\n",
    "        test_metrics = model.evaluate(test_x, test_y, verbose=0)\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": f\"Best_Model_{i}\",\n",
    "            \"Val Loss\": val_metrics[0],\n",
    "            \"Val MSE\": val_metrics[1],\n",
    "            \"Val MAE\": val_metrics[2],\n",
    "            \"Val MAPE\": val_metrics[3],\n",
    "            \"Val RMSE\": val_metrics[4],\n",
    "            \"Test Loss\": test_metrics[0],\n",
    "            \"Test MSE\": test_metrics[1],\n",
    "            \"Test MAE\": test_metrics[2],\n",
    "            \"Test MAPE\": test_metrics[3],\n",
    "            \"Test RMSE\": test_metrics[4]\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Save results\n",
    "    results_file = f'{experiment_name}_evaluation_results.txt'\n",
    "    with open(results_file, 'w') as f:\n",
    "        f.write(f\"Experiment: {experiment_name}\\n\")\n",
    "        f.write(f\"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"\\nEvaluation Results:\\n\")\n",
    "        f.write(results_df.to_string(index=False))\n",
    "    \n",
    "    # Select best model based on test RMSE\n",
    "    best_idx = results_df['Test RMSE'].idxmin()\n",
    "    best_model = best_models[best_idx]\n",
    "    \n",
    "    # Save best model\n",
    "    model_file = f'best_soc_model_{experiment_name}.h5'\n",
    "    best_model.save(model_file)\n",
    "    print(f\"\\nBest model saved as: {model_file}\")\n",
    "    \n",
    "    return best_model, results_df\n",
    "\n",
    "# Execute evaluation\n",
    "best_model, evaluation_results = evaluate_best_models(tuner, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and save the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "hyperparams_file = f'best_hyperparameters_{experiment_name}.txt'\n",
    "with open(hyperparams_file, 'w') as f:\n",
    "    f.write(f\"Best Hyperparameters for {experiment_name}:\\n\")\n",
    "    f.write(f\"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    for key, value in best_hyperparameters.values.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(f\"Best hyperparameters saved to: {hyperparams_file}\")\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for key, value in best_hyperparameters.values.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ae634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture\n",
    "print(\"\\nBest Model Architecture:\")\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64424102",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f01397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "train_predictions = best_model.predict(train_x)\n",
    "test_predictions = best_model.predict(test_x)\n",
    "\n",
    "print(f\"Training predictions shape: {train_predictions.shape}\")\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training results visualization\n",
    "cycle_num = 0\n",
    "steps_num = min(8000, len(train_predictions))  # Ensure we don't exceed array bounds\n",
    "step_index = np.arange(cycle_num*steps_num, min((cycle_num+1)*steps_num, len(train_predictions)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=step_index, \n",
    "    y=train_predictions.flatten()[cycle_num*steps_num:(cycle_num+1)*steps_num],\n",
    "    mode='lines', \n",
    "    name='SoC Predicted',\n",
    "    line=dict(color='red', width=2)\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=step_index, \n",
    "    y=train_y.flatten()[cycle_num*steps_num:(cycle_num+1)*steps_num],\n",
    "    mode='lines', \n",
    "    name='SoC Actual',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=f'Training Results - {experiment_name}',\n",
    "    xaxis_title='Time Steps',\n",
    "    yaxis_title='SoC Percentage',\n",
    "    width=1400,\n",
    "    height=600,\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results visualization\n",
    "cycle_num = 0\n",
    "steps_num = min(1000, len(test_predictions))  # Ensure we don't exceed array bounds\n",
    "step_index = np.arange(cycle_num*steps_num, min((cycle_num+1)*steps_num, len(test_predictions)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=step_index, \n",
    "    y=test_predictions.flatten()[cycle_num*steps_num:(cycle_num+1)*steps_num],\n",
    "    mode='lines', \n",
    "    name='SoC Predicted',\n",
    "    line=dict(color='red', width=2)\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=step_index, \n",
    "    y=test_y.flatten()[cycle_num*steps_num:(cycle_num+1)*steps_num],\n",
    "    mode='lines', \n",
    "    name='SoC Actual',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=f'Test Results - {experiment_name}',\n",
    "    xaxis_title='Time Steps',\n",
    "    yaxis_title='SoC Percentage',\n",
    "    width=1400,\n",
    "    height=600,\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display final metrics\n",
    "test_metrics = best_model.evaluate(test_x, test_y, verbose=0)\n",
    "metric_names = ['Loss', 'MSE', 'MAE', 'MAPE', 'RMSE']\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"FINAL TEST RESULTS - {experiment_name}\")\n",
    "print(\"=\"*50)\n",
    "for name, value in zip(metric_names, test_metrics):\n",
    "    print(f\"{name}: {value:.6f}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
